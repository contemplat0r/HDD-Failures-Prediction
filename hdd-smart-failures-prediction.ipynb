{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предсказание отказов жёстких дисков  с использованием S.M.A.R.T данных собраных в течении года в одном из датацентров [BACKBLAZE](https://www.backblaze.com/b2/hard-drive-test-data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формально, наша задача - Panel Data Forecasting. Panel Data - это обобщение временных рядов (Time Series), когда независимых\n",
    "переменных несколько. Либо же наоборот - временные ряда, являються частным случаем Panel Data.\n",
    "Большая часть методов обращения с Panel Data предполагают заранее известным вид взаимосвязи между текущими значениями переменных\n",
    "и предшествующими а так же вид взаимосвязи между самими переменными (например - нет взаимосвязи, линейная взаимосвязь и т.д.).\n",
    "Здесь используется другой подход: мы не предполагаем заранее известным вид взаимосвязи, как раз ёе мы и должны найти или точнее\n",
    "аппроксимировать используя Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, validation_curve, KFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производим необходимые настройки, присваемаем значения глобальным переменным, создаём список файлов с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/unarch/data_Q*_2019/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_notfeature_columns = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_list_of_columns = [\n",
    "    'date',\n",
    "    'serial_number',\n",
    "    'model',\n",
    "    'capacity_bytes',\n",
    "    'failure',\n",
    "    'smart_3_normalized',\n",
    "    'smart_187_normalized',\n",
    "    'smart_193_normalized',\n",
    "    'smart_195_normalized',\n",
    "    'smart_240_normalized',\n",
    "    'smart_241_normalized'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = sorted(glob.glob(DATA_DIR + '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Определяем функции необходимые для дальнейшей работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_of_nans(datafiles):\n",
    "    df = pd.read_csv(datafiles[0])\n",
    "    total_len = len(df)\n",
    "    num_of_nans = {col_name:len(df.loc[df[col_name].isna()]) for col_name in df.columns.to_list()}\n",
    "    common_col_names_set = set(num_of_nans)\n",
    "    all_col_names_list = df.columns.to_list()\n",
    "    for datafile in datafiles[1:]:\n",
    "        df = pd.read_csv(datafile)\n",
    "        total_len += len(df)\n",
    "        col_names = df.columns.to_list() #[num_n:]\n",
    "        common_col_names_set = common_col_names_set.intersection(set(col_names))\n",
    "        for col_name in col_names:\n",
    "            if col_name in num_of_nans:\n",
    "                num_of_nans[col_name] += len(df.loc[df[col_name].isna()])\n",
    "            else:\n",
    "                num_of_nans[col_name] = len(df.loc[df[col_name].isna()])\n",
    "            if col_name not in all_col_names_list:\n",
    "                col_names_idx = col_names.index(col_name)\n",
    "                precend_col_name = col_names[col_names_idx - 1]\n",
    "                all_col_names_idx = all_col_names_list.index(precend_col_name)\n",
    "                all_col_names_list.insert(all_col_names_idx, col_name)\n",
    "    common_col_names_list = [col_name for col_name in all_col_names_list if col_name in common_col_names_set]            \n",
    "    num_of_nans = {col_name:num_of_nans[col_name] for col_name in common_col_names_set}\n",
    "    gc.collect()\n",
    "    return total_len, num_of_nans, common_col_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dominate_nans_columns(df, drop_column_nan_threshold_ratio=None):\n",
    "    if drop_column_nan_threshold_ratio:\n",
    "        drop_column_nan_threshold = df.shape[0] // drop_column_nan_threshold_ratio\n",
    "    else:\n",
    "        drop_column_nan_threshold = df.shape[0] // 2\n",
    "    return df[\n",
    "        [col for col in df.columns if len(df.loc[df[col].isna()]) < drop_column_nan_threshold]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_column_nans(df, column_name):\n",
    "    #calculate number of NaNs in column\n",
    "    na_len = len(df.loc[df[column_name].isna(), column_name])\n",
    "    #create a pandas series containing values and corresponding quantities from not NaNs part of the column\n",
    "    count_notna = df.loc[df[column_name].notna(), column_name].value_counts()\n",
    "    #calculate relative frequencies (probabilities) of each value\n",
    "    frequencies = count_notna / count_notna.sum()\n",
    "    #make array that contain fill values with the same relative frequencies as in 'not NaN' column part\n",
    "    fill_values = np.array(\n",
    "        [np.random.choice(frequencies.index, p=frequencies.values) for _ in range(na_len)]\n",
    "    )\n",
    "    #fill NaNs\n",
    "    df.loc[df[column_name].isna(), column_name] = fill_values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(df, column_names):\n",
    "    for column_name in column_names:\n",
    "        fill_column_nans(df, column_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(df):\n",
    "    columns_with_nans = df.columns.to_list()[num_notfeature_columns:]\n",
    "    fill_values = {col_name: np.round(df[col_name].astype(np.float64).mean()) for col_name in columns_with_nans}\n",
    "    return df.fillna(value=fill_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" \n",
    "    iterate through all the columns of a dataframe and \n",
    "    modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print(('Memory usage of dataframe is {:.2f}MB').format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print(('Memory usage after optimization is: {:.2f} MB').format(end_mem))\n",
    "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_df(datafiles, total_len, num_of_nans, common_col_names_list, drop_column_nan_threshold_ratio=None):\n",
    "    \n",
    "    if drop_column_nan_threshold_ratio:\n",
    "        drop_column_nan_threshold = total_len // drop_column_nan_threshold_ratio\n",
    "    else:\n",
    "        drop_column_nan_threshold = total_len // 2\n",
    "    \n",
    "    not_dominate_nan_columns = [\n",
    "        col_name for col_name, col_num_of_nans in num_of_nans.items() if col_num_of_nans < drop_column_nan_threshold\n",
    "    ]\n",
    "    \n",
    "    not_dominate_nan_columns = [col_name for col_name in common_col_names_list if col_name in not_dominate_nan_columns]\n",
    "    \n",
    "    data_df = reduce_mem_usage(pd.read_csv(datafiles[0], usecols=not_dominate_nan_columns))\n",
    "    \n",
    "    for datafile in datafiles[1:]:\n",
    "        df = pd.read_csv(datafile, usecols=not_dominate_nan_columns)\n",
    "        data_df = pd.concat([data_df, reduce_mem_usage(df)])\n",
    "    not_dominate_nan_columns[3] = 'failure'\n",
    "    not_dominate_nan_columns[4] = 'capacity_bytes'\n",
    "    \n",
    "    data_df = data_df[not_dominate_nan_columns]\n",
    "    gc.collect()\n",
    "    return data_df.reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_one_hot_encoding(df, scaler):\n",
    "    features_columns = df.columns.to_list()[num_notfeature_columns:]\n",
    "    \n",
    "    scaled_features = pd.DataFrame(\n",
    "        scaler.fit_transform(df[features_columns]), columns=features_columns, index=df.index, dtype=np.float16\n",
    "    )\n",
    "    \n",
    "    return pd.concat(\n",
    "        [df[df.columns.to_list()[:num_notfeature_columns]], scaled_features], axis=1\n",
    "    ).reset_index().drop(['index', 'model', 'date', 'serial_number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precedings_num(begin, end):\n",
    "    return random.randint(begin, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_failure_events_with_preceding(df, preceding_min_subset_len=10, preceding_max_subset_len=40, preceding_len_random=True):\n",
    "    preceding_subset_len = preceding_min_subset_len\n",
    "    if preceding_len_random:\n",
    "        preceding_subset_len = random.randint(preceding_min_subset_len, preceding_max_subset_len)\n",
    "    selected_df = pd.DataFrame()\n",
    "    failure_events = df[df['failure'] == 1]\n",
    "    failure_indexes = failure_events.index.to_list()\n",
    "    for idx in failure_indexes:\n",
    "        preceding = df.loc[(idx - preceding_subset_len):(idx - 1)]\n",
    "        preceding_indexes = preceding.index.to_list()\n",
    "        intersect = set(failure_indexes).intersection(set(preceding_indexes))\n",
    "        if intersect:\n",
    "            selected_df = pd.concat([selected_df, df.loc[(max(intersect) + 1):idx]])\n",
    "        else:\n",
    "            selected_df = pd.concat([selected_df, df.loc[(idx - preceding_subset_len):idx]])\n",
    "    return selected_df.reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_features_and_target(df):\n",
    "    #return df[df.columns.to_list()[num_notfeature_columns:]], df['failure']\n",
    "    return df[df.columns.to_list()[1:]], df['failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_exactly(y_test, y_pred):\n",
    "    false_negatives = 0\n",
    "    false_positives = 0\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    for y_t, y_p in zip(y_test, y_pred):\n",
    "        if y_t == 1 and y_p == 0:\n",
    "            false_negatives += 1\n",
    "        elif y_t == 0 and y_p == 1:\n",
    "            false_positives += 1\n",
    "        elif y_t == 1 and y_p == 1:\n",
    "            true_positives += 1\n",
    "        elif y_t == 0 and y_p == 0:\n",
    "            true_negatives += 1\n",
    "    print(\n",
    "        \"false_negatives: {}, false_positives: {}, true_negatives: {}, true_positives: {}\".format(\n",
    "            false_negatives, false_positives, true_negatives, true_positives)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем количество NaNs в каждом столбце за весь год. Так же (на всякий случай) находим имена столбцов которые встречаються\n",
    "во всех файлах с данными. И вычисляем количество строк в общем датафрейме которые будет создан при обьединении данных содержашихся\n",
    "во всех файлах с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_elapsed: 34.6376409649849 min \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "data_df_total_len, num_of_nans, common_col_names_list = compute_num_of_nans(datafiles)\n",
    "print(\"time_elapsed: {} min \".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём объединённый датафрейм отбрасывая столбцы в которых NaN-ов больше некоторого порога - по умолчанию больше половины \n",
    "количества строк в объединённом датафрейме. Так же производим оптимизацию памяти занимаемой объединённым датафреймом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_elapsed: 80.05467269420623 min \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "data_df = create_data_df(datafiles, data_df_total_len, num_of_nans, common_col_names_list)\n",
    "print(\"time_elapsed: {} min \".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем объединённый датафрейм, что бы в дальнейшем не создавать его каждый раз заново."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_hdf('data_df.hdf5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем NaN-ы в неотброшенных столбцах - т.е. таких в которых NaN-ов меньше половины длинны столбца. Лучший подход здесь - \n",
    "заполение NaN-ов значениями из not NaNs части столбца пропорционально частоте (вероятности) каждого значения. Но это очень медленно , к тому же большая часть столбцов содержит весьма значительное количество уникальных значений, что обессмысливает данный подход.\n",
    "Поэтому NaN-ы заполняються средним арифметическим not NaN значений в столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_elapsed: 0.6688740770022075 min \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ordered_not_nans_data_df = fill_nans(data_df)\n",
    "print(\"time_elapsed: {} min \".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1451"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование данных должно улучшать предсказательную силу ML модели. Так же есть предположение, что частота отказов дисков может  существенно зависить от модели диска. Для того что бы ML модель учла модель диска необходимо использовать one hot encoding. Но строк в объединённом датафрейме 40737546 уникальных значений модели диска 55, при использовании one hot encoding в объединённый датафрейм добавится 55 столбца каждый длинной 40737546, что катастрофически увеличит объём памяти занимаемой датафреймом, было принято решение просто не учитывать модель диска при построении ML модели. В дальнейшем имело бы смысл произвести исследование влияния модел диска на аварийность \"вручную\" используя аппарат математической статистики.\n",
    "Масштабирование в этой версии решения задачи так же не производится, для того что бы посмотреть на предсказательную силу ML модели в наихудшем случае."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "data_df = scale_and_one_hot_encoding(data_df, min_max_scaler)\n",
    "print(\"time_elapsed: {} min \".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_hdf('optimized_data_df.hdf5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_hdf('optimized_data_df.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2263"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df[data_df['failure'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В некотором смысле решающий момент - выборка из объединённого датафрейма данных которые будут переданы ML модели для обучения. Весь датафрейм передавать нет смысла - наличествует очень большой перекос (bias) в данных: 2263 строк в которых значение столбца failure равно 1 (из 40737546 строк). Сколько нибудь сложных методов отбора не используеться, для доказательства работоспособности методики это излишне. Выбираем саму \"аварийную\" строку и несколько предшествующих (в данном случае 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-416-0e65e98c6fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mordered_not_nans_data_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpreceding_min_subset_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpreceding_len_random\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time_elapsed: {} min \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-dfaefa5d114b>\u001b[0m in \u001b[0;36mselect_failure_events_with_preceding\u001b[0;34m(df, preceding_min_subset_len, preceding_max_subset_len, preceding_len_random)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mselected_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersect\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mselected_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpreceding_subset_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mselected_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m--> 473\u001b[0;31m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m             )\n\u001b[1;32m    475\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   2052\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m             b = make_block(\n\u001b[0;32m-> 2054\u001b[0;31m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m    251\u001b[0m     to_concat = [\n\u001b[1;32m    252\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     ]\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m     to_concat = [\n\u001b[1;32m    252\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     ]\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m     func = _get_take_nd_function(\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m     )\n\u001b[1;32m   1721\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_take_nd_function\u001b[0;34m(ndim, arr_dtype, out_dtype, axis, mask_info)\u001b[0m\n\u001b[1;32m   1492\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m         \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_take_1d_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;31m# append bit counts to str, unicode, and void\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflexible\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_isunsized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \"\"\"\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/And-Magic-3.7/lib/python3.7/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \"\"\"\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "selected_data_df = select_failure_events_with_preceding(\n",
    "    ordered_not_nans_data_df,\n",
    "    preceding_min_subset_len=2,\n",
    "    preceding_len_random=False\n",
    ")\n",
    "print(\"time_elapsed: {} min \".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>failure</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_1_raw</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_3_raw</th>\n",
       "      <th>smart_4_normalized</th>\n",
       "      <th>smart_4_raw</th>\n",
       "      <th>smart_5_normalized</th>\n",
       "      <th>smart_5_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_198_normalized</th>\n",
       "      <th>smart_198_raw</th>\n",
       "      <th>smart_199_normalized</th>\n",
       "      <th>smart_199_raw</th>\n",
       "      <th>smart_240_normalized</th>\n",
       "      <th>smart_240_raw</th>\n",
       "      <th>smart_241_normalized</th>\n",
       "      <th>smart_241_raw</th>\n",
       "      <th>smart_242_normalized</th>\n",
       "      <th>smart_242_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84603744.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.349800e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.461635e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.016638e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>108.0</td>\n",
       "      <td>20963336.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.590400e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.458936e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.182198e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>57.0</td>\n",
       "      <td>184212592.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>29616.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.239600e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.950897e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.143129e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.462897e+11</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.957939e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.182294e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>111.0</td>\n",
       "      <td>31901456.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.050900e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.465408e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.114084e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   failure  capacity_bytes  smart_1_normalized  smart_1_raw  \\\n",
       "0        0   8001563222016                79.0   84603744.0   \n",
       "1        0   4000787030016               108.0   20963336.0   \n",
       "2        1   8001563222016                57.0  184212592.0   \n",
       "3        0   4000787030016               100.0          0.0   \n",
       "4        0   4000787030016               111.0   31901456.0   \n",
       "\n",
       "   smart_3_normalized  smart_3_raw  smart_4_normalized  smart_4_raw  \\\n",
       "0                88.0          0.0               100.0          6.0   \n",
       "1                94.0          0.0               100.0          6.0   \n",
       "2                92.0          0.0               100.0          6.0   \n",
       "3               100.0        427.0               100.0          8.0   \n",
       "4                92.0          0.0               100.0          8.0   \n",
       "\n",
       "   smart_5_normalized  smart_5_raw  ...  smart_198_normalized  smart_198_raw  \\\n",
       "0               100.0          0.0  ...                 100.0            0.0   \n",
       "1               100.0          0.0  ...                 100.0            0.0   \n",
       "2                93.0      29616.0  ...                 100.0            0.0   \n",
       "3               100.0          0.0  ...                 100.0            0.0   \n",
       "4               100.0          0.0  ...                 100.0            0.0   \n",
       "\n",
       "   smart_199_normalized  smart_199_raw  smart_240_normalized  smart_240_raw  \\\n",
       "0                 200.0            0.0                 100.0   1.349800e+04   \n",
       "1                 200.0            0.0                 100.0   2.590400e+04   \n",
       "2                 200.0            0.0                 100.0   1.239600e+04   \n",
       "3                 200.0            0.0                 100.0   2.462897e+11   \n",
       "4                 200.0            0.0                 100.0   3.050900e+04   \n",
       "\n",
       "   smart_241_normalized  smart_241_raw  smart_242_normalized  smart_242_raw  \n",
       "0                 100.0   4.461635e+10                 100.0   1.016638e+11  \n",
       "1                 100.0   4.458936e+10                 100.0   1.182198e+11  \n",
       "2                 100.0   3.950897e+10                 100.0   8.143129e+10  \n",
       "3                 100.0   4.957939e+10                 100.0   1.182294e+11  \n",
       "4                 100.0   5.465408e+10                 100.0   1.114084e+11  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные на независмые переменные (features) X и зависимую (target) y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_elapsed: 8.927583694458008e-05 min \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "X, y = divide_features_and_target(selected_data_df)\n",
    "print(\"time_elapsed: {} min \".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_1_raw</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_3_raw</th>\n",
       "      <th>smart_4_normalized</th>\n",
       "      <th>smart_4_raw</th>\n",
       "      <th>smart_5_normalized</th>\n",
       "      <th>smart_5_raw</th>\n",
       "      <th>smart_7_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_198_normalized</th>\n",
       "      <th>smart_198_raw</th>\n",
       "      <th>smart_199_normalized</th>\n",
       "      <th>smart_199_raw</th>\n",
       "      <th>smart_240_normalized</th>\n",
       "      <th>smart_240_raw</th>\n",
       "      <th>smart_241_normalized</th>\n",
       "      <th>smart_241_raw</th>\n",
       "      <th>smart_242_normalized</th>\n",
       "      <th>smart_242_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8001563222016</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84603744.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.349800e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.461635e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.016638e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000787030016</td>\n",
       "      <td>108.0</td>\n",
       "      <td>20963336.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.590400e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.458936e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.182198e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8001563222016</td>\n",
       "      <td>57.0</td>\n",
       "      <td>184212592.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>29616.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.239600e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.950897e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.143129e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000787030016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.462897e+11</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.957939e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.182294e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4000787030016</td>\n",
       "      <td>111.0</td>\n",
       "      <td>31901456.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.050900e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.465408e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.114084e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   capacity_bytes  smart_1_normalized  smart_1_raw  smart_3_normalized  \\\n",
       "0   8001563222016                79.0   84603744.0                88.0   \n",
       "1   4000787030016               108.0   20963336.0                94.0   \n",
       "2   8001563222016                57.0  184212592.0                92.0   \n",
       "3   4000787030016               100.0          0.0               100.0   \n",
       "4   4000787030016               111.0   31901456.0                92.0   \n",
       "\n",
       "   smart_3_raw  smart_4_normalized  smart_4_raw  smart_5_normalized  \\\n",
       "0          0.0               100.0          6.0               100.0   \n",
       "1          0.0               100.0          6.0               100.0   \n",
       "2          0.0               100.0          6.0                93.0   \n",
       "3        427.0               100.0          8.0               100.0   \n",
       "4          0.0               100.0          8.0               100.0   \n",
       "\n",
       "   smart_5_raw  smart_7_normalized  ...  smart_198_normalized  smart_198_raw  \\\n",
       "0          0.0                94.0  ...                 100.0            0.0   \n",
       "1          0.0                84.0  ...                 100.0            0.0   \n",
       "2      29616.0                96.0  ...                 100.0            0.0   \n",
       "3          0.0               100.0  ...                 100.0            0.0   \n",
       "4          0.0                87.0  ...                 100.0            0.0   \n",
       "\n",
       "   smart_199_normalized  smart_199_raw  smart_240_normalized  smart_240_raw  \\\n",
       "0                 200.0            0.0                 100.0   1.349800e+04   \n",
       "1                 200.0            0.0                 100.0   2.590400e+04   \n",
       "2                 200.0            0.0                 100.0   1.239600e+04   \n",
       "3                 200.0            0.0                 100.0   2.462897e+11   \n",
       "4                 200.0            0.0                 100.0   3.050900e+04   \n",
       "\n",
       "   smart_241_normalized  smart_241_raw  smart_242_normalized  smart_242_raw  \n",
       "0                 100.0   4.461635e+10                 100.0   1.016638e+11  \n",
       "1                 100.0   4.458936e+10                 100.0   1.182198e+11  \n",
       "2                 100.0   3.950897e+10                 100.0   8.143129e+10  \n",
       "3                 100.0   4.957939e+10                 100.0   1.182294e+11  \n",
       "4                 100.0   5.465408e+10                 100.0   1.114084e+11  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем данные на обучающие и тестовые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала используем логистическую регрессию в качестве ML модели, далее её используем как базовую для сравнения с более сложными моделями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем prediction на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6823806717737183"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим accuracy невелика, но лучше чем 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1125,    6],\n",
       "       [ 533,   33]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что верно предсказанных сбоев - 33, неверно предсказанных - 6, непредсказанных - 533, верно предсказанных \"несбоев\": 1125 из 1697 событий в тестовой выборке. Результат не очень хороший. Но во общем для логистической регресси это и предполагалось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Далее строим Gradient Boosting модели. Будут использоваться простейшие настройки без тонкого тюнинга моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем XGBoost - очень хорошо зарекомендававшую библиотеку для построения Gradient Boosting моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём pipeline, на случай если в дальнейшем нам надо будет ещё добвавить действия (например дополнительную обработку данных) до или после вызова XGBoost классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline = Pipeline([('xgb', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаём наборы параметров для XGB классификатора. Они будут использованы для поиска по сетке наилучешего набора параметров, с использованием GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'xgb__n_estimators': [10, 50, 100, 500],\n",
    "    'xgb__learning_rate': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "xgb_fit_params = {\n",
    "    'xgb__eval_set': [(X_test, y_test)],\n",
    "    'xgb__early_stopping_rounds': 10,\n",
    "    'xgb__verbose': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_search_cv = GridSearchCV(xgb_pipeline, cv=5, param_grid=xgb_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.124926\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.132587\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.128462\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.127873\n",
      "[6]\tvalidation_0-error:0.125516\n",
      "[9]\tvalidation_0-error:0.123159\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.131408\n",
      "[6]\tvalidation_0-error:0.127283\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.124337\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.124926\n",
      "[12]\tvalidation_0-error:0.125516\n",
      "[15]\tvalidation_0-error:0.124926\n",
      "[18]\tvalidation_0-error:0.125516\n",
      "[21]\tvalidation_0-error:0.126105\n",
      "[24]\tvalidation_0-error:0.125516\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-error:0.124337\n",
      "\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.132587\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.128462\n",
      "[12]\tvalidation_0-error:0.128462\n",
      "[15]\tvalidation_0-error:0.126105\n",
      "[18]\tvalidation_0-error:0.125516\n",
      "[21]\tvalidation_0-error:0.124926\n",
      "[24]\tvalidation_0-error:0.124926\n",
      "[27]\tvalidation_0-error:0.125516\n",
      "[30]\tvalidation_0-error:0.123748\n",
      "[33]\tvalidation_0-error:0.123748\n",
      "[36]\tvalidation_0-error:0.123159\n",
      "[39]\tvalidation_0-error:0.122569\n",
      "[42]\tvalidation_0-error:0.120801\n",
      "[45]\tvalidation_0-error:0.121391\n",
      "[48]\tvalidation_0-error:0.121391\n",
      "[49]\tvalidation_0-error:0.121391\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.127873\n",
      "[6]\tvalidation_0-error:0.125516\n",
      "[9]\tvalidation_0-error:0.123159\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "[15]\tvalidation_0-error:0.123748\n",
      "[18]\tvalidation_0-error:0.124337\n",
      "[21]\tvalidation_0-error:0.126105\n",
      "[24]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[16]\tvalidation_0-error:0.122569\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.131408\n",
      "[6]\tvalidation_0-error:0.127283\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "[12]\tvalidation_0-error:0.123748\n",
      "[15]\tvalidation_0-error:0.125516\n",
      "[18]\tvalidation_0-error:0.125516\n",
      "Stopping. Best iteration:\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.124337\n",
      "[12]\tvalidation_0-error:0.124337\n",
      "[15]\tvalidation_0-error:0.124337\n",
      "[18]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-error:0.124337\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.124926\n",
      "[12]\tvalidation_0-error:0.125516\n",
      "[15]\tvalidation_0-error:0.124926\n",
      "[18]\tvalidation_0-error:0.125516\n",
      "[21]\tvalidation_0-error:0.126105\n",
      "[24]\tvalidation_0-error:0.125516\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-error:0.124337\n",
      "\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.132587\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.128462\n",
      "[12]\tvalidation_0-error:0.128462\n",
      "[15]\tvalidation_0-error:0.126105\n",
      "[18]\tvalidation_0-error:0.125516\n",
      "[21]\tvalidation_0-error:0.124926\n",
      "[24]\tvalidation_0-error:0.124926\n",
      "[27]\tvalidation_0-error:0.125516\n",
      "[30]\tvalidation_0-error:0.123748\n",
      "[33]\tvalidation_0-error:0.123748\n",
      "[36]\tvalidation_0-error:0.123159\n",
      "[39]\tvalidation_0-error:0.122569\n",
      "[42]\tvalidation_0-error:0.120801\n",
      "[45]\tvalidation_0-error:0.121391\n",
      "[48]\tvalidation_0-error:0.121391\n",
      "[51]\tvalidation_0-error:0.120801\n",
      "[54]\tvalidation_0-error:0.122569\n",
      "[57]\tvalidation_0-error:0.123748\n",
      "Stopping. Best iteration:\n",
      "[47]\tvalidation_0-error:0.120212\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.127873\n",
      "[6]\tvalidation_0-error:0.125516\n",
      "[9]\tvalidation_0-error:0.123159\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "[15]\tvalidation_0-error:0.123748\n",
      "[18]\tvalidation_0-error:0.124337\n",
      "[21]\tvalidation_0-error:0.126105\n",
      "[24]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[16]\tvalidation_0-error:0.122569\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.131408\n",
      "[6]\tvalidation_0-error:0.127283\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "[12]\tvalidation_0-error:0.123748\n",
      "[15]\tvalidation_0-error:0.125516\n",
      "[18]\tvalidation_0-error:0.125516\n",
      "Stopping. Best iteration:\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.124337\n",
      "[12]\tvalidation_0-error:0.124337\n",
      "[15]\tvalidation_0-error:0.124337\n",
      "[18]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-error:0.124337\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.124926\n",
      "[12]\tvalidation_0-error:0.125516\n",
      "[15]\tvalidation_0-error:0.124926\n",
      "[18]\tvalidation_0-error:0.125516\n",
      "[21]\tvalidation_0-error:0.126105\n",
      "[24]\tvalidation_0-error:0.125516\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-error:0.124337\n",
      "\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.132587\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.128462\n",
      "[12]\tvalidation_0-error:0.128462\n",
      "[15]\tvalidation_0-error:0.126105\n",
      "[18]\tvalidation_0-error:0.125516\n",
      "[21]\tvalidation_0-error:0.124926\n",
      "[24]\tvalidation_0-error:0.124926\n",
      "[27]\tvalidation_0-error:0.125516\n",
      "[30]\tvalidation_0-error:0.123748\n",
      "[33]\tvalidation_0-error:0.123748\n",
      "[36]\tvalidation_0-error:0.123159\n",
      "[39]\tvalidation_0-error:0.122569\n",
      "[42]\tvalidation_0-error:0.120801\n",
      "[45]\tvalidation_0-error:0.121391\n",
      "[48]\tvalidation_0-error:0.121391\n",
      "[51]\tvalidation_0-error:0.120801\n",
      "[54]\tvalidation_0-error:0.122569\n",
      "[57]\tvalidation_0-error:0.123748\n",
      "Stopping. Best iteration:\n",
      "[47]\tvalidation_0-error:0.120212\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.127873\n",
      "[6]\tvalidation_0-error:0.125516\n",
      "[9]\tvalidation_0-error:0.123159\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "[15]\tvalidation_0-error:0.123748\n",
      "[18]\tvalidation_0-error:0.124337\n",
      "[21]\tvalidation_0-error:0.126105\n",
      "[24]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[16]\tvalidation_0-error:0.122569\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.131408\n",
      "[6]\tvalidation_0-error:0.127283\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "[12]\tvalidation_0-error:0.123748\n",
      "[15]\tvalidation_0-error:0.125516\n",
      "[18]\tvalidation_0-error:0.125516\n",
      "Stopping. Best iteration:\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.124337\n",
      "[12]\tvalidation_0-error:0.124337\n",
      "[15]\tvalidation_0-error:0.124337\n",
      "[18]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-error:0.124337\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.124337\n",
      "[9]\tvalidation_0-error:0.122569\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.126694\n",
      "[9]\tvalidation_0-error:0.126105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.13023\n",
      "[6]\tvalidation_0-error:0.124337\n",
      "[9]\tvalidation_0-error:0.124337\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.128462\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.126105\n",
      "[6]\tvalidation_0-error:0.123748\n",
      "[9]\tvalidation_0-error:0.122569\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.124337\n",
      "[9]\tvalidation_0-error:0.122569\n",
      "[12]\tvalidation_0-error:0.126105\n",
      "[15]\tvalidation_0-error:0.124337\n",
      "[18]\tvalidation_0-error:0.123159\n",
      "[21]\tvalidation_0-error:0.120801\n",
      "[24]\tvalidation_0-error:0.122569\n",
      "[27]\tvalidation_0-error:0.119623\n",
      "[30]\tvalidation_0-error:0.12198\n",
      "[33]\tvalidation_0-error:0.12198\n",
      "[36]\tvalidation_0-error:0.123748\n",
      "Stopping. Best iteration:\n",
      "[26]\tvalidation_0-error:0.119623\n",
      "\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.126694\n",
      "[9]\tvalidation_0-error:0.126105\n",
      "[12]\tvalidation_0-error:0.123748\n",
      "[15]\tvalidation_0-error:0.126694\n",
      "[18]\tvalidation_0-error:0.126105\n",
      "[21]\tvalidation_0-error:0.126694\n",
      "[24]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-error:0.123159\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.13023\n",
      "[6]\tvalidation_0-error:0.124337\n",
      "[9]\tvalidation_0-error:0.124337\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "[15]\tvalidation_0-error:0.124337\n",
      "[18]\tvalidation_0-error:0.124337\n",
      "[21]\tvalidation_0-error:0.126105\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.128462\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "[12]\tvalidation_0-error:0.120801\n",
      "[15]\tvalidation_0-error:0.121391\n",
      "[18]\tvalidation_0-error:0.12198\n",
      "[21]\tvalidation_0-error:0.12198\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-error:0.120801\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.126105\n",
      "[6]\tvalidation_0-error:0.123748\n",
      "[9]\tvalidation_0-error:0.122569\n",
      "[12]\tvalidation_0-error:0.123748\n",
      "[15]\tvalidation_0-error:0.121391\n",
      "[18]\tvalidation_0-error:0.126105\n",
      "Stopping. Best iteration:\n",
      "[10]\tvalidation_0-error:0.121391\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.124337\n",
      "[9]\tvalidation_0-error:0.122569\n",
      "[12]\tvalidation_0-error:0.126105\n",
      "[15]\tvalidation_0-error:0.124337\n",
      "[18]\tvalidation_0-error:0.123159\n",
      "[21]\tvalidation_0-error:0.120801\n",
      "[24]\tvalidation_0-error:0.122569\n",
      "[27]\tvalidation_0-error:0.119623\n",
      "[30]\tvalidation_0-error:0.12198\n",
      "[33]\tvalidation_0-error:0.12198\n",
      "[36]\tvalidation_0-error:0.123748\n",
      "Stopping. Best iteration:\n",
      "[26]\tvalidation_0-error:0.119623\n",
      "\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.126694\n",
      "[9]\tvalidation_0-error:0.126105\n",
      "[12]\tvalidation_0-error:0.123748\n",
      "[15]\tvalidation_0-error:0.126694\n",
      "[18]\tvalidation_0-error:0.126105\n",
      "[21]\tvalidation_0-error:0.126694\n",
      "[24]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-error:0.123159\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.13023\n",
      "[6]\tvalidation_0-error:0.124337\n",
      "[9]\tvalidation_0-error:0.124337\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "[15]\tvalidation_0-error:0.124337\n",
      "[18]\tvalidation_0-error:0.124337\n",
      "[21]\tvalidation_0-error:0.126105\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.128462\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "[12]\tvalidation_0-error:0.120801\n",
      "[15]\tvalidation_0-error:0.121391\n",
      "[18]\tvalidation_0-error:0.12198\n",
      "[21]\tvalidation_0-error:0.12198\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-error:0.120801\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.126105\n",
      "[6]\tvalidation_0-error:0.123748\n",
      "[9]\tvalidation_0-error:0.122569\n",
      "[12]\tvalidation_0-error:0.123748\n",
      "[15]\tvalidation_0-error:0.121391\n",
      "[18]\tvalidation_0-error:0.126105\n",
      "Stopping. Best iteration:\n",
      "[10]\tvalidation_0-error:0.121391\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.124337\n",
      "[9]\tvalidation_0-error:0.122569\n",
      "[12]\tvalidation_0-error:0.126105\n",
      "[15]\tvalidation_0-error:0.124337\n",
      "[18]\tvalidation_0-error:0.123159\n",
      "[21]\tvalidation_0-error:0.120801\n",
      "[24]\tvalidation_0-error:0.122569\n",
      "[27]\tvalidation_0-error:0.119623\n",
      "[30]\tvalidation_0-error:0.12198\n",
      "[33]\tvalidation_0-error:0.12198\n",
      "[36]\tvalidation_0-error:0.123748\n",
      "Stopping. Best iteration:\n",
      "[26]\tvalidation_0-error:0.119623\n",
      "\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129641\n",
      "[6]\tvalidation_0-error:0.126694\n",
      "[9]\tvalidation_0-error:0.126105\n",
      "[12]\tvalidation_0-error:0.123748\n",
      "[15]\tvalidation_0-error:0.126694\n",
      "[18]\tvalidation_0-error:0.126105\n",
      "[21]\tvalidation_0-error:0.126694\n",
      "[24]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-error:0.123159\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.13023\n",
      "[6]\tvalidation_0-error:0.124337\n",
      "[9]\tvalidation_0-error:0.124337\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "[15]\tvalidation_0-error:0.124337\n",
      "[18]\tvalidation_0-error:0.124337\n",
      "[21]\tvalidation_0-error:0.126105\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.128462\n",
      "[9]\tvalidation_0-error:0.123748\n",
      "[12]\tvalidation_0-error:0.120801\n",
      "[15]\tvalidation_0-error:0.121391\n",
      "[18]\tvalidation_0-error:0.12198\n",
      "[21]\tvalidation_0-error:0.12198\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-error:0.120801\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.126105\n",
      "[6]\tvalidation_0-error:0.123748\n",
      "[9]\tvalidation_0-error:0.122569\n",
      "[12]\tvalidation_0-error:0.123748\n",
      "[15]\tvalidation_0-error:0.121391\n",
      "[18]\tvalidation_0-error:0.126105\n",
      "Stopping. Best iteration:\n",
      "[10]\tvalidation_0-error:0.121391\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.141426\n",
      "[6]\tvalidation_0-error:0.133176\n",
      "[9]\tvalidation_0-error:0.134355\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.130819\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.129051\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.136123\n",
      "[6]\tvalidation_0-error:0.13789\n",
      "[9]\tvalidation_0-error:0.135533\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.123748\n",
      "[9]\tvalidation_0-error:0.126694\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.137301\n",
      "[6]\tvalidation_0-error:0.127873\n",
      "[9]\tvalidation_0-error:0.129641\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.141426\n",
      "[6]\tvalidation_0-error:0.133176\n",
      "[9]\tvalidation_0-error:0.134355\n",
      "[12]\tvalidation_0-error:0.124337\n",
      "[15]\tvalidation_0-error:0.142015\n",
      "[18]\tvalidation_0-error:0.144372\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-error:0.123748\n",
      "\n",
      "[0]\tvalidation_0-error:0.13023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.130819\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.129051\n",
      "[12]\tvalidation_0-error:0.133176\n",
      "[15]\tvalidation_0-error:0.131408\n",
      "Stopping. Best iteration:\n",
      "[5]\tvalidation_0-error:0.126694\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.136123\n",
      "[6]\tvalidation_0-error:0.13789\n",
      "[9]\tvalidation_0-error:0.135533\n",
      "Stopping. Best iteration:\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.123748\n",
      "[9]\tvalidation_0-error:0.126694\n",
      "[12]\tvalidation_0-error:0.128462\n",
      "[15]\tvalidation_0-error:0.132587\n",
      "[18]\tvalidation_0-error:0.135533\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-error:0.12198\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.137301\n",
      "[6]\tvalidation_0-error:0.127873\n",
      "[9]\tvalidation_0-error:0.129641\n",
      "[12]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[2]\tvalidation_0-error:0.119034\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.141426\n",
      "[6]\tvalidation_0-error:0.133176\n",
      "[9]\tvalidation_0-error:0.134355\n",
      "[12]\tvalidation_0-error:0.124337\n",
      "[15]\tvalidation_0-error:0.142015\n",
      "[18]\tvalidation_0-error:0.144372\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-error:0.123748\n",
      "\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.130819\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.129051\n",
      "[12]\tvalidation_0-error:0.133176\n",
      "[15]\tvalidation_0-error:0.131408\n",
      "Stopping. Best iteration:\n",
      "[5]\tvalidation_0-error:0.126694\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.136123\n",
      "[6]\tvalidation_0-error:0.13789\n",
      "[9]\tvalidation_0-error:0.135533\n",
      "Stopping. Best iteration:\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.123748\n",
      "[9]\tvalidation_0-error:0.126694\n",
      "[12]\tvalidation_0-error:0.128462\n",
      "[15]\tvalidation_0-error:0.132587\n",
      "[18]\tvalidation_0-error:0.135533\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-error:0.12198\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.137301\n",
      "[6]\tvalidation_0-error:0.127873\n",
      "[9]\tvalidation_0-error:0.129641\n",
      "[12]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[2]\tvalidation_0-error:0.119034\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.141426\n",
      "[6]\tvalidation_0-error:0.133176\n",
      "[9]\tvalidation_0-error:0.134355\n",
      "[12]\tvalidation_0-error:0.124337\n",
      "[15]\tvalidation_0-error:0.142015\n",
      "[18]\tvalidation_0-error:0.144372\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-error:0.123748\n",
      "\n",
      "[0]\tvalidation_0-error:0.13023\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.130819\n",
      "[6]\tvalidation_0-error:0.131408\n",
      "[9]\tvalidation_0-error:0.129051\n",
      "[12]\tvalidation_0-error:0.133176\n",
      "[15]\tvalidation_0-error:0.131408\n",
      "Stopping. Best iteration:\n",
      "[5]\tvalidation_0-error:0.126694\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.136123\n",
      "[6]\tvalidation_0-error:0.13789\n",
      "[9]\tvalidation_0-error:0.135533\n",
      "Stopping. Best iteration:\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.128462\n",
      "[6]\tvalidation_0-error:0.123748\n",
      "[9]\tvalidation_0-error:0.126694\n",
      "[12]\tvalidation_0-error:0.128462\n",
      "[15]\tvalidation_0-error:0.132587\n",
      "[18]\tvalidation_0-error:0.135533\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-error:0.12198\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.137301\n",
      "[6]\tvalidation_0-error:0.127873\n",
      "[9]\tvalidation_0-error:0.129641\n",
      "[12]\tvalidation_0-error:0.126694\n",
      "Stopping. Best iteration:\n",
      "[2]\tvalidation_0-error:0.119034\n",
      "\n",
      "[0]\tvalidation_0-error:0.129641\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[3]\tvalidation_0-error:0.129051\n",
      "[6]\tvalidation_0-error:0.123159\n",
      "[9]\tvalidation_0-error:0.12198\n",
      "[12]\tvalidation_0-error:0.123159\n",
      "[15]\tvalidation_0-error:0.123748\n",
      "[18]\tvalidation_0-error:0.120801\n",
      "[21]\tvalidation_0-error:0.12198\n",
      "Stopping. Best iteration:\n",
      "[11]\tvalidation_0-error:0.120801\n",
      "\n",
      "elapsed time: 0.15679389238357544 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "xgb_search_cv.fit(X_train, y_train, **xgb_fit_params)\n",
    "print(\"elapsed time: {} min\".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же как и для логистической регресси находим prediction на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_search_cv.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8791985857395404"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим accuracy уже значительно лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1079,   52],\n",
       "       [ 153,  413]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим XGBoost верно предсказал 413 отказов, неверно предсказал 52 отказа, не предсказал 153, верно предсказал 1079 \"неотказов\" что уже можно использовать в \"боевой\" обстановке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее используем LightGBM - библиотеку соперничающюю с XGBoost в эффективности. Производим те же самые шаги что и для XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pipeline = Pipeline([('lgbm', LGBMClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_param_grid = {\n",
    "    'lgbm__n_estimators': [10, 50, 100, 500],\n",
    "    'lgbm__learning_rate': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "lgbm_fit_params = {\n",
    "    'lgbm__early_stopping_rounds': 30, \n",
    "    'lgbm__eval_metric': 'auc', \n",
    "    'lgbm__eval_set': [(X_test,y_test)],\n",
    "    'lgbm__eval_names': 'valid',\n",
    "    'lgbm__verbose': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search_cv = GridSearchCV(lgbm_pipeline, cv=5, param_grid=lgbm_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's auc: 0.892011\tvalid's binary_logloss: 0.398001\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9]\tvalid's auc: 0.890071\tvalid's binary_logloss: 0.401398\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's auc: 0.893327\tvalid's binary_logloss: 0.390988\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[8]\tvalid's auc: 0.892503\tvalid's binary_logloss: 0.410426\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6]\tvalid's auc: 0.892297\tvalid's binary_logloss: 0.444032\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[22]\tvalid's auc: 0.895938\tvalid's binary_logloss: 0.34861\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[24]\tvalid's auc: 0.896319\tvalid's binary_logloss: 0.34544\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[22]\tvalid's auc: 0.898331\tvalid's binary_logloss: 0.342934\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid's auc: 0.898007\tvalid's binary_logloss: 0.347399\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[25]\tvalid's auc: 0.900873\tvalid's binary_logloss: 0.344286\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid's auc: 0.895938\tvalid's binary_logloss: 0.34861\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid's auc: 0.896319\tvalid's binary_logloss: 0.34544\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid's auc: 0.898331\tvalid's binary_logloss: 0.342934\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid's auc: 0.898007\tvalid's binary_logloss: 0.347399\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid's auc: 0.900873\tvalid's binary_logloss: 0.344286\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid's auc: 0.895938\tvalid's binary_logloss: 0.34861\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid's auc: 0.896319\tvalid's binary_logloss: 0.34544\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid's auc: 0.898331\tvalid's binary_logloss: 0.342934\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid's auc: 0.898007\tvalid's binary_logloss: 0.347399\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid's auc: 0.900873\tvalid's binary_logloss: 0.344286\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4]\tvalid's auc: 0.894241\tvalid's binary_logloss: 0.349494\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3]\tvalid's auc: 0.891489\tvalid's binary_logloss: 0.365258\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5]\tvalid's auc: 0.886614\tvalid's binary_logloss: 0.353559\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9]\tvalid's auc: 0.889959\tvalid's binary_logloss: 0.365455\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4]\tvalid's auc: 0.887841\tvalid's binary_logloss: 0.355326\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.894241\tvalid's binary_logloss: 0.349494\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.891489\tvalid's binary_logloss: 0.365258\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.88657\tvalid's binary_logloss: 0.353129\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.888897\tvalid's binary_logloss: 0.350134\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.887841\tvalid's binary_logloss: 0.355326\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.894241\tvalid's binary_logloss: 0.349494\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.891489\tvalid's binary_logloss: 0.365258\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.88657\tvalid's binary_logloss: 0.353129\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.888897\tvalid's binary_logloss: 0.350134\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.887841\tvalid's binary_logloss: 0.355326\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.894241\tvalid's binary_logloss: 0.349494\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.891489\tvalid's binary_logloss: 0.365258\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.88657\tvalid's binary_logloss: 0.353129\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.888897\tvalid's binary_logloss: 0.350134\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.887841\tvalid's binary_logloss: 0.355326\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid's auc: 0.890572\tvalid's binary_logloss: 0.360682\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid's auc: 0.881894\tvalid's binary_logloss: 0.380298\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid's auc: 0.877633\tvalid's binary_logloss: 0.371273\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid's auc: 0.888061\tvalid's binary_logloss: 0.354206\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid's auc: 0.884003\tvalid's binary_logloss: 0.365203\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.890572\tvalid's binary_logloss: 0.360682\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.879387\tvalid's binary_logloss: 0.363692\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.877633\tvalid's binary_logloss: 0.371273\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.888061\tvalid's binary_logloss: 0.354206\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.884003\tvalid's binary_logloss: 0.365203\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.890572\tvalid's binary_logloss: 0.360682\n",
      "Training until validation scores don't improve for 30 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.879387\tvalid's binary_logloss: 0.363692\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.877633\tvalid's binary_logloss: 0.371273\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.888061\tvalid's binary_logloss: 0.354206\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.884003\tvalid's binary_logloss: 0.365203\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.890572\tvalid's binary_logloss: 0.360682\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.879387\tvalid's binary_logloss: 0.363692\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.877633\tvalid's binary_logloss: 0.371273\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.888061\tvalid's binary_logloss: 0.354206\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.884003\tvalid's binary_logloss: 0.365203\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[23]\tvalid's auc: 0.899345\tvalid's binary_logloss: 0.342753\n",
      "elapsed time: 0.1969814936319987 min\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lgbm_search_cv.fit(X_train, y_train, **lgbm_fit_params)\n",
    "print(\"elapsed time: {} min\".format((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgbm = lgbm_search_cv.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8768414849734826"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ж accuracy относительно неплох и примерно равен accuracy для XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме accuracy вычисляем roc auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8414080537877296"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roc auc относительно неплох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1072,   59],\n",
       "       [ 150,  416]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion matrix выглядит чуть получше чем у XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем прдсказания XGBoost и LightGBM (ставим 1 там где хотя бы одна из моделей ставит 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_lgbm = pd.Series(y_pred_xgb).combine(pd.Series(y_pred_lgbm), lambda u, v: u or v, fill_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803771361225693"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_xgb_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8489149350304462"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_xgb_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1067,   64],\n",
       "       [ 139,  427]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_xgb_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим посредством объединения удалось добиться некоторого улучшения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же небезинтересно было бы посмотреть на кривые обучения. Определяем вспомогательные функции для \"рисования\" соответствующих графиков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(train_sizes, train_scores, test_scores, title, alpha=0.1, measure='accuracy'):\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.plot(train_sizes, train_mean, label='train score', color='blue', marker='o')\n",
    "    \n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        train_mean + train_std,\n",
    "        train_mean - train_std,\n",
    "        color='blue',\n",
    "        alpha=alpha\n",
    "    )\n",
    "    \n",
    "    plt.plot(\n",
    "        train_sizes,\n",
    "        test_mean,\n",
    "        label='test score',\n",
    "        color='red',\n",
    "        marker='o'\n",
    "    )\n",
    "\n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        test_mean + test_std,\n",
    "        test_mean - test_std,\n",
    "        color='red',\n",
    "        alpha=alpha\n",
    "    )\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Number of training points\")\n",
    "    plt.ylabel(\"Measure {}\".format(measure))\n",
    "    plt.grid(ls='--')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_validation_curve(param_range, train_scores, test_scores, title, alpha=0.1):\n",
    "    param_range = [x[1] for x in param_range] \n",
    "    sort_idx = np.argsort(param_range)\n",
    "    param_range=np.array(param_range)[sort_idx]\n",
    "    train_mean = np.mean(train_scores, axis=1)[sort_idx]\n",
    "    train_std = np.std(train_scores, axis=1)[sort_idx]\n",
    "    test_mean = np.mean(test_scores, axis=1)[sort_idx]\n",
    "    test_std = np.std(test_scores, axis=1)[sort_idx]\n",
    "    plt.plot(param_range, train_mean, label='train score', color='blue', marker='o')\n",
    "    plt.fill_between(\n",
    "        param_range,\n",
    "        train_mean + train_std,\n",
    "        train_mean - train_std,\n",
    "        color='blue',\n",
    "        alpha=alpha\n",
    "    )\n",
    "    plt.plot(param_range, test_mean, label='test score', color='red', marker='o')\n",
    "    plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, color='red', alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.grid(ls='--')\n",
    "    plt.xlabel('Weight of class 2')\n",
    "    plt.ylabel('Average values and standard deviation for F1-Score')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 648x432 with 0 Axes>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 648x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_sizes, xgb_train_scores, xgb_test_scores = learning_curve(\n",
    "    estimator=xgb_search_cv.best_estimator_,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    train_sizes=np.arange(0.1, 1.1, 0.1),\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs= 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(\n",
    "    xgb_train_sizes,\n",
    "    xgb_train_scores,\n",
    "    xgb_test_scores,\n",
    "    title='Learning curve for XGBoost'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train_sizes, lgbm_train_scores, lgbm_test_scores = learning_curve(\n",
    "    estimator=lgbm_search_cv.best_estimator_,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    train_sizes=np.arange(0.1, 1.1, 0.1),\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs= 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(\n",
    "    lgbm_train_sizes,\n",
    "    lgbm_train_scores,\n",
    "    lgbm_test_scores,\n",
    "    title=\"Learning curve for LightGBM\",\n",
    "    measure=\"roc_auc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, кривые обучения пока далеки от совершенства."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот Jupyter notebook всего лишь prof of concepts.\n",
    "В дальнейшем, используя более изощрённые методы борьбы с перекошенностью данных (сложные алгоритмы выбора, либо построения дополнитель точек отказа), используя более сложные модели (Neural Networks различных видов) и более тонко настраивая их скорее всего можно будет добиться очень сильного уменьшения ложных предсказаний/\"непредсказаний\" и увеличения правильных предсказаний.\n",
    "Так же имеет смысл рассмотреть эту задачу как anomaly detection задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'serial_number',\n",
       " 'model',\n",
       " 'failure',\n",
       " 'capacity_bytes',\n",
       " 'smart_1_normalized',\n",
       " 'smart_1_raw',\n",
       " 'smart_3_normalized',\n",
       " 'smart_3_raw',\n",
       " 'smart_4_normalized',\n",
       " 'smart_4_raw',\n",
       " 'smart_5_normalized',\n",
       " 'smart_5_raw',\n",
       " 'smart_7_normalized',\n",
       " 'smart_7_raw',\n",
       " 'smart_9_normalized',\n",
       " 'smart_9_raw',\n",
       " 'smart_10_normalized',\n",
       " 'smart_10_raw',\n",
       " 'smart_12_normalized',\n",
       " 'smart_12_raw',\n",
       " 'smart_187_normalized',\n",
       " 'smart_187_raw',\n",
       " 'smart_188_normalized',\n",
       " 'smart_188_raw',\n",
       " 'smart_190_normalized',\n",
       " 'smart_190_raw',\n",
       " 'smart_192_normalized',\n",
       " 'smart_192_raw',\n",
       " 'smart_193_normalized',\n",
       " 'smart_193_raw',\n",
       " 'smart_194_normalized',\n",
       " 'smart_194_raw',\n",
       " 'smart_195_normalized',\n",
       " 'smart_195_raw',\n",
       " 'smart_197_normalized',\n",
       " 'smart_197_raw',\n",
       " 'smart_198_normalized',\n",
       " 'smart_198_raw',\n",
       " 'smart_199_normalized',\n",
       " 'smart_199_raw',\n",
       " 'smart_240_normalized',\n",
       " 'smart_240_raw',\n",
       " 'smart_241_normalized',\n",
       " 'smart_241_raw',\n",
       " 'smart_242_normalized',\n",
       " 'smart_242_raw']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head(10).to_json('smart_short_0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>model</th>\n",
       "      <th>failure</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_1_raw</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_3_raw</th>\n",
       "      <th>smart_4_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_198_normalized</th>\n",
       "      <th>smart_198_raw</th>\n",
       "      <th>smart_199_normalized</th>\n",
       "      <th>smart_199_raw</th>\n",
       "      <th>smart_240_normalized</th>\n",
       "      <th>smart_240_raw</th>\n",
       "      <th>smart_241_normalized</th>\n",
       "      <th>smart_241_raw</th>\n",
       "      <th>smart_242_normalized</th>\n",
       "      <th>smart_242_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Z305B2QN</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>0</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>111.0</td>\n",
       "      <td>35673128.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>26461.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.553972e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.183566e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>ZJV0XJQ4</td>\n",
       "      <td>ST12000NM0007</td>\n",
       "      <td>0</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>83.0</td>\n",
       "      <td>187116872.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.887057e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.160959e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>ZJV0XJQ3</td>\n",
       "      <td>ST12000NM0007</td>\n",
       "      <td>0</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>73.0</td>\n",
       "      <td>19599104.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.111459e+09</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.441231e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>ZJV0XJQ0</td>\n",
       "      <td>ST12000NM0007</td>\n",
       "      <td>0</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>81.0</td>\n",
       "      <td>136943696.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4166.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.350759e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.938334e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>PL1331LAHG1S4H</td>\n",
       "      <td>HGST HMS5C4040ALE640</td>\n",
       "      <td>0</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>ZA16NQJR</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>0</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>83.0</td>\n",
       "      <td>203857808.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14652.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.771906e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.485711e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>ZJV02XWG</td>\n",
       "      <td>ST12000NM0007</td>\n",
       "      <td>0</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>81.0</td>\n",
       "      <td>116523736.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5512.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.504775e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.612356e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>ZJV1CSVX</td>\n",
       "      <td>ST12000NM0007</td>\n",
       "      <td>0</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>82.0</td>\n",
       "      <td>171431192.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3949.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.536406e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.122348e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>ZJV02XWA</td>\n",
       "      <td>ST12000NM0007</td>\n",
       "      <td>0</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>84.0</td>\n",
       "      <td>241650824.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5631.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.126671e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.614299e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>ZA18CEBS</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>0</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>82.0</td>\n",
       "      <td>177605672.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11625.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.124180e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.541220e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   serial_number                 model  failure  capacity_bytes  \\\n",
       "0  2019-01-01        Z305B2QN           ST4000DM000        0   4000787030016   \n",
       "1  2019-01-01        ZJV0XJQ4         ST12000NM0007        0  12000138625024   \n",
       "2  2019-01-01        ZJV0XJQ3         ST12000NM0007        0  12000138625024   \n",
       "3  2019-01-01        ZJV0XJQ0         ST12000NM0007        0  12000138625024   \n",
       "4  2019-01-01  PL1331LAHG1S4H  HGST HMS5C4040ALE640        0   4000787030016   \n",
       "5  2019-01-01        ZA16NQJR          ST8000NM0055        0   8001563222016   \n",
       "6  2019-01-01        ZJV02XWG         ST12000NM0007        0  12000138625024   \n",
       "7  2019-01-01        ZJV1CSVX         ST12000NM0007        0  12000138625024   \n",
       "8  2019-01-01        ZJV02XWA         ST12000NM0007        0  12000138625024   \n",
       "9  2019-01-01        ZA18CEBS          ST8000NM0055        0   8001563222016   \n",
       "\n",
       "   smart_1_normalized  smart_1_raw  smart_3_normalized  smart_3_raw  \\\n",
       "0               111.0   35673128.0                91.0          0.0   \n",
       "1                83.0  187116872.0                98.0          0.0   \n",
       "2                73.0   19599104.0                99.0          0.0   \n",
       "3                81.0  136943696.0                93.0          0.0   \n",
       "4               100.0          0.0               100.0        436.0   \n",
       "5                83.0  203857808.0                92.0          0.0   \n",
       "6                81.0  116523736.0                92.0          0.0   \n",
       "7                82.0  171431192.0                98.0          0.0   \n",
       "8                84.0  241650824.0                97.0          0.0   \n",
       "9                82.0  177605672.0                97.0          0.0   \n",
       "\n",
       "   smart_4_normalized  ...  smart_198_normalized  smart_198_raw  \\\n",
       "0               100.0  ...                 100.0            0.0   \n",
       "1               100.0  ...                 100.0            0.0   \n",
       "2               100.0  ...                 100.0            0.0   \n",
       "3               100.0  ...                 100.0            0.0   \n",
       "4               100.0  ...                 100.0            0.0   \n",
       "5               100.0  ...                 100.0            0.0   \n",
       "6               100.0  ...                 100.0            0.0   \n",
       "7               100.0  ...                 100.0            0.0   \n",
       "8               100.0  ...                 100.0            0.0   \n",
       "9               100.0  ...                 100.0            0.0   \n",
       "\n",
       "   smart_199_normalized  smart_199_raw  smart_240_normalized  smart_240_raw  \\\n",
       "0                 200.0            0.0                 100.0        26461.0   \n",
       "1                 200.0            0.0                 100.0         3020.0   \n",
       "2                 200.0            0.0                 100.0          670.0   \n",
       "3                 200.0            0.0                 100.0         4166.0   \n",
       "4                 200.0            0.0                   NaN            NaN   \n",
       "5                 200.0            0.0                 100.0        14652.0   \n",
       "6                 200.0            0.0                 100.0         5512.0   \n",
       "7                 200.0            0.0                 100.0         3949.0   \n",
       "8                 200.0            0.0                 100.0         5631.0   \n",
       "9                 200.0            0.0                 100.0        11625.0   \n",
       "\n",
       "   smart_241_normalized  smart_241_raw  smart_242_normalized  smart_242_raw  \n",
       "0                 100.0   4.553972e+10                 100.0   1.183566e+11  \n",
       "1                 100.0   2.887057e+10                 100.0   2.160959e+10  \n",
       "2                 100.0   6.111459e+09                 100.0   7.441231e+08  \n",
       "3                 100.0   3.350759e+10                 100.0   3.938334e+10  \n",
       "4                   NaN            NaN                   NaN            NaN  \n",
       "5                 100.0   4.771906e+10                 100.0   9.485711e+10  \n",
       "6                 100.0   3.504775e+10                 100.0   4.612356e+10  \n",
       "7                 100.0   3.536406e+10                 100.0   4.122348e+10  \n",
       "8                 100.0   4.126671e+10                 100.0   5.614299e+10  \n",
       "9                 100.0   4.124180e+10                 100.0   8.541220e+10  \n",
       "\n",
       "[10 rows x 47 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('xgb',\n",
       "   XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "                 colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "                 learning_rate=0.5, max_delta_step=0, max_depth=3,\n",
       "                 min_child_weight=1, missing=None, n_estimators=50, n_jobs=1,\n",
       "                 nthread=None, objective='binary:logistic', random_state=0,\n",
       "                 reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "                 silent=None, subsample=1, verbosity=1))],\n",
       " 'verbose': False,\n",
       " 'xgb': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "               learning_rate=0.5, max_delta_step=0, max_depth=3,\n",
       "               min_child_weight=1, missing=None, n_estimators=50, n_jobs=1,\n",
       "               nthread=None, objective='binary:logistic', random_state=0,\n",
       "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "               silent=None, subsample=1, verbosity=1),\n",
       " 'xgb__base_score': 0.5,\n",
       " 'xgb__booster': 'gbtree',\n",
       " 'xgb__colsample_bylevel': 1,\n",
       " 'xgb__colsample_bynode': 1,\n",
       " 'xgb__colsample_bytree': 1,\n",
       " 'xgb__gamma': 0,\n",
       " 'xgb__learning_rate': 0.5,\n",
       " 'xgb__max_delta_step': 0,\n",
       " 'xgb__max_depth': 3,\n",
       " 'xgb__min_child_weight': 1,\n",
       " 'xgb__missing': None,\n",
       " 'xgb__n_estimators': 50,\n",
       " 'xgb__n_jobs': 1,\n",
       " 'xgb__nthread': None,\n",
       " 'xgb__objective': 'binary:logistic',\n",
       " 'xgb__random_state': 0,\n",
       " 'xgb__reg_alpha': 0,\n",
       " 'xgb__reg_lambda': 1,\n",
       " 'xgb__scale_pos_weight': 1,\n",
       " 'xgb__seed': None,\n",
       " 'xgb__silent': None,\n",
       " 'xgb__subsample': 1,\n",
       " 'xgb__verbosity': 1}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('lgbm',\n",
       "   LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                  importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                  min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                  n_estimators=50, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                  random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                  subsample=1.0, subsample_for_bin=200000, subsample_freq=0))],\n",
       " 'verbose': False,\n",
       " 'lgbm': LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                n_estimators=50, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       " 'lgbm__boosting_type': 'gbdt',\n",
       " 'lgbm__class_weight': None,\n",
       " 'lgbm__colsample_bytree': 1.0,\n",
       " 'lgbm__importance_type': 'split',\n",
       " 'lgbm__learning_rate': 0.1,\n",
       " 'lgbm__max_depth': -1,\n",
       " 'lgbm__min_child_samples': 20,\n",
       " 'lgbm__min_child_weight': 0.001,\n",
       " 'lgbm__min_split_gain': 0.0,\n",
       " 'lgbm__n_estimators': 50,\n",
       " 'lgbm__n_jobs': -1,\n",
       " 'lgbm__num_leaves': 31,\n",
       " 'lgbm__objective': None,\n",
       " 'lgbm__random_state': None,\n",
       " 'lgbm__reg_alpha': 0.0,\n",
       " 'lgbm__reg_lambda': 0.0,\n",
       " 'lgbm__silent': True,\n",
       " 'lgbm__subsample': 1.0,\n",
       " 'lgbm__subsample_for_bin': 200000,\n",
       " 'lgbm__subsample_freq': 0}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_search_cv.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    #'base_score': 0.5,\n",
    "    'booster': 'gbtree',\n",
    "    #'colsample_bylevel': 1,\n",
    "    #'colsample_bynode': 1,\n",
    "    #'colsample_bytree': 1,\n",
    "    #'gamma': 0,\n",
    "    'eval_set': [(X_test.values, y_test.values)],\n",
    "    'learning_rate': 0.5,\n",
    "    'max_delta_step': 0,\n",
    "    #'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'missing': None,\n",
    "    'n_estimators': 50,\n",
    "    'n_jobs': 1,\n",
    "    'nthread': None,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 0,\n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 1,\n",
    "    'scale_pos_weight': 1,\n",
    "    'seed': None,\n",
    "    'silent': None,\n",
    "    'subsample': 1,\n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_clf = XGBClassifier(xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_clf_boost = xgb_clf.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart_3_normalized',\n",
       " 'smart_3_raw',\n",
       " 'smart_4_normalized',\n",
       " 'smart_4_raw',\n",
       " 'smart_5_normalized',\n",
       " 'smart_5_raw',\n",
       " 'smart_7_normalized',\n",
       " 'smart_7_raw',\n",
       " 'smart_9_normalized',\n",
       " 'smart_9_raw',\n",
       " 'smart_10_normalized',\n",
       " 'smart_10_raw',\n",
       " 'smart_12_normalized',\n",
       " 'smart_12_raw',\n",
       " 'smart_187_normalized',\n",
       " 'smart_187_raw',\n",
       " 'smart_188_normalized',\n",
       " 'smart_188_raw',\n",
       " 'smart_190_normalized',\n",
       " 'smart_190_raw',\n",
       " 'smart_192_normalized',\n",
       " 'smart_192_raw',\n",
       " 'smart_193_normalized',\n",
       " 'smart_193_raw',\n",
       " 'smart_194_normalized',\n",
       " 'smart_194_raw',\n",
       " 'smart_195_normalized',\n",
       " 'smart_195_raw',\n",
       " 'smart_197_normalized',\n",
       " 'smart_197_raw',\n",
       " 'smart_198_normalized',\n",
       " 'smart_198_raw',\n",
       " 'smart_199_normalized',\n",
       " 'smart_199_raw',\n",
       " 'smart_240_normalized',\n",
       " 'smart_240_raw',\n",
       " 'smart_241_normalized',\n",
       " 'smart_241_raw',\n",
       " 'smart_242_normalized',\n",
       " 'smart_242_raw']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: failure, dtype: int8"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster='gbtree',\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.5,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=50,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective='binary:logistic',\n",
    "    random_state=0,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=3,\n",
    "    #eval_set=[(X_test.values, y_test.values)]\n",
    "    early_stopping_rounds=10,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    #eval_metric='roc_auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:00] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:01] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[18:32:01] INFO: /home/conda/feedstock_root/build_artifacts/xgboost_1572314959925/work/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_boost = xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_clf = xgb_clf_boost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1070,   61],\n",
       "       [ 151,  415]])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_boost.save_model('xgb_clf_boost.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_clf_boost.save_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_clf_boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_booster = xgboost.Booster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_booster.load_model('xgb_clf_boost.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_xgb_clf = xgb_clf_booster.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_file = open('xgb_clf.pkl', 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb_clf_boost, xgb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_file = open('xgb_clf.pkl', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(xgb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_load_xgb_clf = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1070,   61],\n",
       "       [ 151,  415]])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_load_xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    class_weight=None,\n",
    "    colsample_bytree=1.0,\n",
    "    importance_type='split',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=20,\n",
    "    min_child_weight=0.001,\n",
    "    min_split_gain=0.0,\n",
    "    n_estimators=50,\n",
    "    n_jobs=2,\n",
    "    num_leaves=31,\n",
    "    objective=None,\n",
    "    random_state=None,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    silent=True,\n",
    "    subsample=1.0,\n",
    "    subsample_for_bin=200000,\n",
    "    subsample_freq=0,\n",
    "    eval_metric='auc',\n",
    "    eval_set=[(X_test,y_test)],\n",
    "    eval_names=['valid'],\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf_model = lgbm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgbm_clf_model = lgbm_clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1066,   65],\n",
       "       [ 145,  421]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_lgbm_clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pickle_file = open('lgbm_clf.pkl', 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lgbm_clf_model, lgbm_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pickle_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pickle_file = open('lgbm_clf.pkl', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_lgbm_clf_model = pickle.load(lgbm_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_load_lgbm_clf = loaded_lgbm_clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1066,   65],\n",
       "       [ 145,  421]])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_load_lgbm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_1_raw</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_3_raw</th>\n",
       "      <th>smart_4_normalized</th>\n",
       "      <th>smart_4_raw</th>\n",
       "      <th>smart_5_normalized</th>\n",
       "      <th>smart_5_raw</th>\n",
       "      <th>smart_7_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_198_normalized</th>\n",
       "      <th>smart_198_raw</th>\n",
       "      <th>smart_199_normalized</th>\n",
       "      <th>smart_199_raw</th>\n",
       "      <th>smart_240_normalized</th>\n",
       "      <th>smart_240_raw</th>\n",
       "      <th>smart_241_normalized</th>\n",
       "      <th>smart_241_raw</th>\n",
       "      <th>smart_242_normalized</th>\n",
       "      <th>smart_242_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>4000787030016</td>\n",
       "      <td>113.0</td>\n",
       "      <td>57808064.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.462400e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.347337e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.524582e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5090</th>\n",
       "      <td>12000138625024</td>\n",
       "      <td>63.0</td>\n",
       "      <td>236845536.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>34368.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.540800e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.844313e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.571357e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5091</th>\n",
       "      <td>12000138625024</td>\n",
       "      <td>84.0</td>\n",
       "      <td>226688784.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.528000e+04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.739927e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.364408e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5092</th>\n",
       "      <td>8001563222016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.462897e+11</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.957939e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.182294e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>500107862016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.957939e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.182294e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      capacity_bytes  smart_1_normalized  smart_1_raw  smart_3_normalized  \\\n",
       "5089   4000787030016               113.0   57808064.0                94.0   \n",
       "5090  12000138625024                63.0  236845536.0                90.0   \n",
       "5091  12000138625024                84.0  226688784.0                97.0   \n",
       "5092   8001563222016               100.0          0.0               100.0   \n",
       "5093    500107862016               100.0          0.0               100.0   \n",
       "\n",
       "      smart_3_raw  smart_4_normalized  smart_4_raw  smart_5_normalized  \\\n",
       "5089          0.0               100.0          6.0               100.0   \n",
       "5090          0.0               100.0         13.0                42.0   \n",
       "5091          0.0               100.0          3.0               100.0   \n",
       "5092          0.0               100.0          2.0               100.0   \n",
       "5093       1489.0               100.0          6.0               100.0   \n",
       "\n",
       "      smart_5_raw  smart_7_normalized  ...  smart_198_normalized  \\\n",
       "5089          0.0                88.0  ...                 100.0   \n",
       "5090      34368.0                81.0  ...                 100.0   \n",
       "5091          0.0                76.0  ...                 100.0   \n",
       "5092          0.0               100.0  ...                 100.0   \n",
       "5093          0.0               100.0  ...                 100.0   \n",
       "\n",
       "      smart_198_raw  smart_199_normalized  smart_199_raw  \\\n",
       "5089            0.0                 200.0            0.0   \n",
       "5090            8.0                 200.0            0.0   \n",
       "5091            0.0                 200.0            0.0   \n",
       "5092            0.0                 200.0            0.0   \n",
       "5093            0.0                 200.0            0.0   \n",
       "\n",
       "      smart_240_normalized  smart_240_raw  smart_241_normalized  \\\n",
       "5089                 100.0   3.462400e+04                 100.0   \n",
       "5090                 100.0   1.540800e+04                 100.0   \n",
       "5091                 100.0   1.528000e+04                 100.0   \n",
       "5092                 100.0   2.462897e+11                 100.0   \n",
       "5093                 100.0   0.000000e+00                 100.0   \n",
       "\n",
       "      smart_241_raw  smart_242_normalized  smart_242_raw  \n",
       "5089   5.347337e+10                 100.0   1.524582e+11  \n",
       "5090   6.844313e+10                 100.0   1.571357e+11  \n",
       "5091   6.739927e+10                 100.0   1.364408e+11  \n",
       "5092   4.957939e+10                 100.0   1.182294e+11  \n",
       "5093   4.957939e+10                 100.0   1.182294e+11  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape((3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
